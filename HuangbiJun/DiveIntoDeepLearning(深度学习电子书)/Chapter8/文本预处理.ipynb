{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"文本预处理.ipynb","provenance":[],"authorship_tag":"ABX9TyMLeqOH7UggreNhuP3UADGy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["解析文本的常见预处理步骤。这些步骤通常包括：\n","\n","1.将文本作为字符串加载到内存中。\n","\n","2.将字符串拆分为词元（如单词和字符）。\n","\n","3.建立一个词表，将拆分的词元映射到数字索引。\n","\n","4.将文本转换为数字索引序列，方便模型操作。"],"metadata":{"id":"rtmpjjyEK_fx"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"48Og40W3KqlM","executionInfo":{"status":"ok","timestamp":1660209148266,"user_tz":-480,"elapsed":31190,"user":{"displayName":"宋清一","userId":"09404435184606863398"}},"outputId":"8ca37d0a-6d87-4944-9fbb-a77b57350308"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting d2l\n","  Downloading d2l-0.17.5-py3-none-any.whl (82 kB)\n","\u001b[K     |████████████████████████████████| 82 kB 204 kB/s \n","\u001b[?25hCollecting numpy==1.21.5\n","  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n","\u001b[K     |████████████████████████████████| 15.7 MB 56.6 MB/s \n","\u001b[?25hRequirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.7/dist-packages (from d2l) (1.0.0)\n","Collecting requests==2.25.1\n","  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 8.1 MB/s \n","\u001b[?25hCollecting pandas==1.2.4\n","  Downloading pandas-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 38.6 MB/s \n","\u001b[?25hCollecting matplotlib==3.5.1\n","  Downloading matplotlib-3.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n","\u001b[K     |████████████████████████████████| 11.2 MB 45.1 MB/s \n","\u001b[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.2.0)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.3.1)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.6.1)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (7.7.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (4.10.1)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.3.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (7.1.2)\n","Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (1.4.4)\n","Collecting fonttools>=4.22.0\n","  Downloading fonttools-4.34.4-py3-none-any.whl (944 kB)\n","\u001b[K     |████████████████████████████████| 944 kB 41.5 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (0.11.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (21.3)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.4->d2l) (2022.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (2022.6.15)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (3.0.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.5.1->d2l) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.1->d2l) (1.15.0)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.3.5)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.1.1)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.5.0)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.1.1)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.8.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (4.4.2)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (57.4.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (1.0.18)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (2.6.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.2.5)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (0.2.0)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.6.1)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (1.1.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.8.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (2.11.3)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (5.4.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.13.3)\n","Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (4.11.1)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter==1.0.0->d2l) (23.2.0)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter==1.0.0->d2l) (0.7.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter==1.0.0->d2l) (2.0.1)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.6.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.8.4)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.4)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.0.1)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.0)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter==1.0.0->d2l) (2.16.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter==1.0.0->d2l) (4.3.3)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter==1.0.0->d2l) (22.1.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter==1.0.0->d2l) (5.9.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter==1.0.0->d2l) (0.18.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter==1.0.0->d2l) (4.12.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook->jupyter==1.0.0->d2l) (3.8.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\n","Requirement already satisfied: qtpy>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter==1.0.0->d2l) (2.1.0)\n","Installing collected packages: numpy, fonttools, requests, pandas, matplotlib, d2l\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.3.5\n","    Uninstalling pandas-1.3.5:\n","      Successfully uninstalled pandas-1.3.5\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","Successfully installed d2l-0.17.5 fonttools-4.34.4 matplotlib-3.5.1 numpy-1.21.5 pandas-1.2.4 requests-2.25.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["matplotlib","mpl_toolkits","numpy"]}}},"metadata":{}}],"source":["!pip install d2l\n","import collections\n","import re\n","from d2l import torch as d2l"]},{"cell_type":"markdown","source":["首先，从H.G.Well的时光机器中加载文本。 这是一个相当小的语料库，只有30000多个单词，但足够我们小试牛刀， 而现实中的文档集合可能会包含数十亿个单词。 下面的函数将数据集读取到由多条文本行组成的列表中，其中每条文本行都是一个字符串。 为简单起见，我们在这里忽略了标点符号和字母大写。"],"metadata":{"id":"277J6UAzLsUP"}},{"cell_type":"code","source":["d2l.DATA_HUB['time_machine'] = (d2l.DATA_URL + 'timemachine.txt',\n","                                '090b5e7e70c295757f55df93cb0a180b9691891a')\n","\n","def read_time_machine(): \n","    \"\"\"将时间机器数据集加载到文本行的列表中\"\"\"\n","    with open(d2l.download('time_machine'), 'r') as f:\n","        lines = f.readlines()\n","    # re.sub()函数将非字符元素变为空格，strip()移除字符串头尾指定的字符(默认为空格或换行符)或字符序列，lower()将所有字符转化为小写\n","    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]\n","\n","lines = read_time_machine()\n","print(f'# 文本总行数: {len(lines)}')\n","print(lines[0])\n","print(lines[8])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t3QEjGIbLJAX","executionInfo":{"status":"ok","timestamp":1660209698832,"user_tz":-480,"elapsed":434,"user":{"displayName":"宋清一","userId":"09404435184606863398"}},"outputId":"5b5dd5b6-2144-4d92-98f3-4ce8db8a43a3"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["# 文本总行数: 3221\n","the time machine by h g wells\n","the time traveller for so it will be convenient to speak of him\n"]}]},{"cell_type":"markdown","source":["下面的tokenize函数将文本行列表（lines）作为输入， 列表中的每个元素是一个文本序列（如一条文本行）。 每个文本序列又被拆分成一个词元列表，词元（token）是文本的基本单位。 最后，返回一个由词元列表组成的列表，其中的每个词元都是一个字符串（string）。"],"metadata":{"id":"Io0vIFo_MoPJ"}},{"cell_type":"code","source":["def tokenize(lines, token='word'):\n","    \"\"\"将文本行拆分为单词或字符词元\"\"\"\n","    if token == 'word':\n","        return [line.split() for line in lines]\n","    elif token == 'char':\n","        return [list(line) for line in lines]\n","    else:\n","        print('错误：未知词元类型：' + token)\n","\n","tokens = tokenize(lines)\n","for i in range(11):\n","    print(tokens[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5rh_a4_CLvFh","executionInfo":{"status":"ok","timestamp":1660209586990,"user_tz":-480,"elapsed":511,"user":{"displayName":"宋清一","userId":"09404435184606863398"}},"outputId":"71fe1bf1-84c1-4f8a-eead-8623aaba2fe0"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["['the', 'time', 'machine', 'by', 'h', 'g', 'wells']\n","[]\n","[]\n","[]\n","[]\n","['i']\n","[]\n","[]\n","['the', 'time', 'traveller', 'for', 'so', 'it', 'will', 'be', 'convenient', 'to', 'speak', 'of', 'him']\n","['was', 'expounding', 'a', 'recondite', 'matter', 'to', 'us', 'his', 'grey', 'eyes', 'shone', 'and']\n","['twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated', 'the']\n"]}]},{"cell_type":"markdown","source":["词元的类型是字符串，而模型需要的输入是数字，因此这种类型不方便模型使用。 现在，让我们构建一个字典，通常也叫做词表（vocabulary）， 用来将字符串类型的词元映射到从$0$开始的数字索引中。 我们先将训练集中的所有文档合并在一起，对它们的唯一词元进行统计， 得到的统计结果称之为语料（corpus）。 然后根据每个唯一词元的出现频率，为其分配一个数字索引。 很少出现的词元通常被移除，这可以降低复杂性。 另外，语料库中不存在或已删除的任何词元都将映射到一个特定的未知词元“$<unk>$”。 我们可以选择增加一个列表，用于保存那些被保留的词元， 例如：填充词元（“$<pad>$”）； 序列开始词元（“$<bos>$”）； 序列结束词元（“$<eos>$”）。"],"metadata":{"id":"BnsadVYGNeqh"}},{"cell_type":"code","source":["class Vocab: \n","    \"\"\"文本词表\"\"\"\n","    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n","        if tokens is None:\n","            tokens = []\n","        if reserved_tokens is None:\n","            reserved_tokens = []\n","        # 按出现频率排序\n","        counter = count_corpus(tokens)\n","        # sorted()函数\n","        # key -- 主要是用来进行比较的元素，只有一个参数，具体的函数的参数就是取自于可迭代对象中，指定可迭代对象中的一个元素来进行排序。\n","        # reverse -- 排序规则，reverse = True 降序 ， reverse = False 升序（默认）。\n","        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n","                                   reverse=True)\n","        # 未知词元的索引为0\n","        self.idx_to_token = ['<unk>'] + reserved_tokens\n","        self.token_to_idx = {token: idx\n","                             for idx, token in enumerate(self.idx_to_token)}\n","        for token, freq in self._token_freqs:\n","            if freq < min_freq:\n","                break\n","            if token not in self.token_to_idx:\n","                self.idx_to_token.append(token)\n","                self.token_to_idx[token] = len(self.idx_to_token) - 1\n","\n","    def __len__(self):\n","        return len(self.idx_to_token)\n","\n","    def __getitem__(self, tokens):\n","        if not isinstance(tokens, (list, tuple)):\n","            return self.token_to_idx.get(tokens, self.unk)\n","        return [self.__getitem__(token) for token in tokens]\n","\n","    def to_tokens(self, indices):\n","        if not isinstance(indices, (list, tuple)):\n","            return self.idx_to_token[indices]\n","        return [self.idx_to_token[index] for index in indices]\n","\n","    @property\n","    def unk(self):  # 未知词元的索引为0\n","        return 0\n","\n","    @property\n","    def token_freqs(self):\n","        return self._token_freqs\n","\n","def count_corpus(tokens):  \n","    \"\"\"统计词元的频率\"\"\"\n","    # 这里的tokens是1D列表或2D列表\n","    if len(tokens) == 0 or isinstance(tokens[0], list):\n","        # 将词元列表展平成一个列表\n","        tokens = [token for line in tokens for token in line]\n","    return collections.Counter(tokens)"],"metadata":{"id":"Abapf-j-M96O","executionInfo":{"status":"ok","timestamp":1660212369385,"user_tz":-480,"elapsed":3,"user":{"displayName":"宋清一","userId":"09404435184606863398"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["vocab = Vocab(tokens)\n","print(list(vocab.token_to_idx.items())[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kqU3pRJKXlVF","executionInfo":{"status":"ok","timestamp":1660212376260,"user_tz":-480,"elapsed":392,"user":{"displayName":"宋清一","userId":"09404435184606863398"}},"outputId":"d19daacd-e334-4b55-f653-1333b3b52cc4"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[('<unk>', 0), ('the', 1), ('i', 2), ('and', 3), ('of', 4), ('a', 5), ('to', 6), ('was', 7), ('in', 8), ('that', 9)]\n"]}]},{"cell_type":"code","source":["for i in [0, 10]:\n","    print('文本:', tokens[i])\n","    print('索引:', vocab[tokens[i]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ewg3tb73Xm8-","executionInfo":{"status":"ok","timestamp":1660212383621,"user_tz":-480,"elapsed":659,"user":{"displayName":"宋清一","userId":"09404435184606863398"}},"outputId":"34bfdfa0-ae2b-4280-8b72-cc9999e0f1b3"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["文本: ['the', 'time', 'machine', 'by', 'h', 'g', 'wells']\n","索引: [1, 19, 50, 40, 2183, 2184, 400]\n","文本: ['twinkled', 'and', 'his', 'usually', 'pale', 'face', 'was', 'flushed', 'and', 'animated', 'the']\n","索引: [2186, 3, 25, 1044, 362, 113, 7, 1421, 3, 1045, 1]\n"]}]},{"cell_type":"code","source":["def load_corpus_time_machine(max_tokens=-1):  \n","    \"\"\"返回时光机器数据集的词元索引列表和词表\"\"\"\n","    lines = read_time_machine()\n","    tokens = tokenize(lines, 'char')\n","    vocab = Vocab(tokens)\n","    # 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落，\n","    # 所以将所有文本行展平到一个列表中\n","    corpus = [vocab[token] for line in tokens for token in line]\n","    if max_tokens > 0:\n","        corpus = corpus[:max_tokens]\n","    return corpus, vocab\n","\n","corpus, vocab = load_corpus_time_machine()\n","len(corpus), len(vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nZ2QEfFeXos8","executionInfo":{"status":"ok","timestamp":1660212404683,"user_tz":-480,"elapsed":391,"user":{"displayName":"宋清一","userId":"09404435184606863398"}},"outputId":"faf5ccc1-eed5-470f-dd3f-ef4722332ede"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(170580, 28)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":[""],"metadata":{"id":"dlgJnQAXXqyP"},"execution_count":null,"outputs":[]}]}